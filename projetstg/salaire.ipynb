{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importation des bib nécessaires \n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bech ybotti al chemin mta les csv\n",
    "\n",
    "path = r'C:\\Users\\Lenovo\\Desktop\\etl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#liste des fichier csv\n",
    "file_list = glob.glob(os.path.join(path, '*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mettre les données dans un frame tableau kima nkolou\n",
    "data_frames = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pour lire plusieurs fichiers csv et les stocker dans un dataframe /dictionnaire\n",
    "for file in file_list:\n",
    "    try:\n",
    "        filename = os.path.basename(file)\n",
    "        df = pd.read_csv(file,sep=';') #3al fekra separateur heka 7atitou 5ater fel les fichiers csv sa3at ijiw fy naffs il colonne denya ilkol iwali ki yal9alek \";\" ya3mel separation mabin les elements mte3ek\n",
    "        data_frames[filename] = df\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"Error reading file {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sk_performance statut_performance\n",
      "0               1           Confirme\n",
      "1               2             Senior\n",
      "2               3             Junior\n",
      "3               4      Junior Anapec\n",
      "4               5      non renseigne\n"
     ]
    }
   ],
   "source": [
    "#traitement ya9ra fel les données fichier mtaek csv\n",
    "df_performance = data_frames['performance.csv']\n",
    "print(df_performance.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sk_salaire  sk_employee  sk_contrat  sk_emploi  sk_departement  \\\n",
      "0           1            1           1          1               1   \n",
      "1           2            2           1          2               1   \n",
      "2           3            3           1          3               1   \n",
      "3           4            4           1          2               1   \n",
      "4           5            5           1          3               1   \n",
      "\n",
      "   sk_motif_mobilite  sk_qualification  sk_classification  sk_performance  \\\n",
      "0                  1                 1                  1               1   \n",
      "1                  1                 2                  2               1   \n",
      "2                  1                 3                  1               2   \n",
      "3                  1                 2                  2               3   \n",
      "4                  1                 3                  1               2   \n",
      "\n",
      "   sk_date_entree  sk_date_effet  montant_salaire  augmentation_salaire  \\\n",
      "0               1              1         450000.0               25000.0   \n",
      "1               1              2         450000.0               25000.0   \n",
      "2               1              3         316800.0               19200.0   \n",
      "3               1              4         425000.0              108200.0   \n",
      "4               1              5         316800.0                   0.0   \n",
      "\n",
      "   taux_augmentation  \n",
      "0              5.882  \n",
      "1              5.882  \n",
      "2              6.452  \n",
      "3             34.154  \n",
      "4              0.000  \n"
     ]
    }
   ],
   "source": [
    "df_salaire = data_frames['fact_salaire.csv']\n",
    "print(df_salaire.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sk_classification classification\n",
      "0                  1            EMP\n",
      "1                  2            CAS\n",
      "2                  3            CAD\n",
      "3                  4            DIR\n",
      "4                  5             ST\n"
     ]
    }
   ],
   "source": [
    "df_classification = data_frames['classification.csv']\n",
    "print(df_classification.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sk_employee matricule date_entree_grpe date_debut_contrat      sexe  \\\n",
      "0           1    M00260       25/09/2016         01/08/2017  Masculin   \n",
      "1           2    M00267       25/09/2016         01/07/2017  Masculin   \n",
      "2           3    M00273       25/09/2016         25/09/2016  Masculin   \n",
      "3           4    M00333       25/09/2016         01/07/2017  Masculin   \n",
      "4           5    M00334       25/09/2016         25/09/2016  Masculin   \n",
      "\n",
      "    qualite date_naissance situation_familiale debut_situation_familiale  \\\n",
      "0  Monsieur     12/09/1980            Marie(e)                25/09/2016   \n",
      "1  Monsieur     06/05/1976            Marie(e)                25/09/2016   \n",
      "2  Monsieur     06/11/1983            Marie(e)                25/09/2016   \n",
      "3  Monsieur     01/04/1967            Marie(e)                25/09/2016   \n",
      "4  Monsieur     15/08/1968            Marie(e)                25/09/2016   \n",
      "\n",
      "  premier_emploi matricule_manager              droit_congee  \\\n",
      "0            Oui             38493  Droit 1,5 jours par mois   \n",
      "1            Oui             30795  Droit 1,5 jours par mois   \n",
      "2            Non             30795  Droit 1,5 jours par mois   \n",
      "3            Oui             30795  Droit 1,5 jours par mois   \n",
      "4            Non             30795  Droit 1,5 jours par mois   \n",
      "\n",
      "       mode_paiement  anciennete statut  \n",
      "0  Virement bancaire           7  actif  \n",
      "1  Virement bancaire           7  actif  \n",
      "2  Virement bancaire           7  actif  \n",
      "3  Virement bancaire           7  actif  \n",
      "4  Virement bancaire           7  actif  \n"
     ]
    }
   ],
   "source": [
    "df_employee = data_frames['employee.csv']\n",
    "print(df_employee.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sk_emploi                 emploi\n",
      "0          1   CONSEILLER TECHNIQUE\n",
      "1          2            TEAM LEADER\n",
      "2          3    CHARGE DE CLIENTELE\n",
      "3          4     QUALITY CONTROLLER\n",
      "4          5  CONSEILLER COMMERCIAL\n"
     ]
    }
   ],
   "source": [
    "df_emploi = data_frames['emploi.csv']\n",
    "print(df_emploi.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sk_departement         departement\n",
      "0               1          Production\n",
      "1               2  Support production\n",
      "2               3       Administratif\n",
      "3               4          Management\n"
     ]
    }
   ],
   "source": [
    "df_dep = data_frames['departement.csv']\n",
    "print(df_dep.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sk_qualification qualification\n",
      "0                 1            E2\n",
      "1                 2            A2\n",
      "2                 3            E1\n",
      "3                 4            E3\n",
      "4                 5            E4\n"
     ]
    }
   ],
   "source": [
    "df_qual = data_frames['qualification.csv']\n",
    "print(df_qual.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sk_production  sk_employee  sk_emploi  sk_departement  sk_qualification  \\\n",
      "0              1            1          1               1                 1   \n",
      "1              2            2          2               1                 2   \n",
      "2              3            3          3               1                 3   \n",
      "3              4            4          2               1                 2   \n",
      "4              5            5          3               1                 3   \n",
      "\n",
      "   sk_classification  sk_performance  sk_date_evaluation  note_perf_ajustee  \\\n",
      "0                  1               1                   1                107   \n",
      "1                  2               1                   1                114   \n",
      "2                  1               2                   1                110   \n",
      "3                  2               3                   1                103   \n",
      "4                  1               2                   1                110   \n",
      "\n",
      "   note_perf_globale  \n",
      "0                  4  \n",
      "1                  4  \n",
      "2                  4  \n",
      "3                  3  \n",
      "4                  4  \n"
     ]
    }
   ],
   "source": [
    "df_factprod = data_frames['fact_prod.csv']\n",
    "print(df_factprod.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sk_salaire  sk_employee  sk_contrat  sk_emploi  sk_departement  \\\n",
      "0           1            1           1          1               1   \n",
      "1           2            2           1          2               1   \n",
      "2           3            3           1          3               1   \n",
      "3           4            4           1          2               1   \n",
      "4           5            5           1          3               1   \n",
      "\n",
      "   sk_motif_mobilite  sk_qualification  sk_classification  sk_performance  \\\n",
      "0                  1                 1                  1               1   \n",
      "1                  1                 2                  2               1   \n",
      "2                  1                 3                  1               2   \n",
      "3                  1                 2                  2               3   \n",
      "4                  1                 3                  1               2   \n",
      "\n",
      "   sk_date_entree  sk_date_effet  montant_salaire  augmentation_salaire  \\\n",
      "0               1              1         450000.0               25000.0   \n",
      "1               1              2         450000.0               25000.0   \n",
      "2               1              3         316800.0               19200.0   \n",
      "3               1              4         425000.0              108200.0   \n",
      "4               1              5         316800.0                   0.0   \n",
      "\n",
      "   taux_augmentation  \n",
      "0              5.882  \n",
      "1              5.882  \n",
      "2              6.452  \n",
      "3             34.154  \n",
      "4              0.000  \n"
     ]
    }
   ],
   "source": [
    "df_factsal = data_frames['fact_salaire.csv']\n",
    "print(df_factsal.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sk_classification', 'classification', 'sk_contrat', 'type_contrat',\n",
      "       'nature_contrat', 'libelle_contrat', '1', 'Production',\n",
      "       'sk_departement', 'departement', 'sk_date_effet', 'date_effet', 'annee',\n",
      "       'sk_emploi', 'emploi', 'sk_employee', 'matricule', 'date_entree_grpe',\n",
      "       'date_debut_contrat', 'sexe', 'qualite', 'date_naissance',\n",
      "       'situation_familiale', 'debut_situation_familiale', 'premier_emploi',\n",
      "       'matricule_manager', 'droit_congee', 'mode_paiement', 'anciennete',\n",
      "       'statut', 'sk_date_entree', 'mois', 'jour', 'sk_date_evaluation',\n",
      "       'date_evaluation', 'sk_production', 'sk_qualification',\n",
      "       'sk_performance', 'note_perf_ajustee', 'note_perf_globale',\n",
      "       'sk_salaire', 'sk_motif_mobilite', 'montant_salaire',\n",
      "       'augmentation_salaire', 'taux_augmentation', 'statut_performance',\n",
      "       'qualification'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Concaténer tous les DataFrames en un seul DataFrame\n",
    "data = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "# Supprimer les lignes avec des valeurs manquantes (si nécessaire)\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Supprimer les espaces supplémentaires dans les noms de colonnes\n",
    "data.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "\n",
    "# Vérifier les noms de colonnes après la correction\n",
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 4.37\n",
      "P-value: 0.04\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#test annova <0.05 donc il est singnificatif donc il' ya une relation entre montant salaire et classification (impact)\n",
    "\n",
    "\n",
    "# Perform the ANOVA test\n",
    "f_statistic, p_value = f_oneway(df_salaire['montant_salaire'], df_classification['sk_classification'])\n",
    "\n",
    "# Calculate the total sum of squares (TSS)\n",
    "tss = np.sum((df_salaire['montant_salaire'] - df_salaire['montant_salaire'].mean())**2)\n",
    "\n",
    "# Calculate the between-group sum of squares (SSB)\n",
    "group_means = df_salaire.groupby('sk_classification')['montant_salaire'].mean()\n",
    "ssb = np.sum((group_means - df_salaire['montant_salaire'].mean())**2)\n",
    "\n",
    "# Calculate eta-squared (η²)\n",
    "eta_squared = ssb / tss\n",
    "\n",
    "print(f\"F-statistic: {f_statistic:.2f}\")\n",
    "print(f\"P-value: {p_value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 195.54\n",
      "P-value: 0.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#test annova montant salaire et sk emploi <0.05 fortement significatif\n",
    "\n",
    "\n",
    "# Perform the ANOVA test\n",
    "f_statistic, p_value = f_oneway(df_salaire['montant_salaire'], df_emploi['sk_emploi'])\n",
    "\n",
    "# Calculate the total sum of squares (TSS)\n",
    "tss = np.sum((df_salaire['montant_salaire'] - df_salaire['montant_salaire'].mean())**2)\n",
    "\n",
    "# Calculate the between-group sum of squares (SSB)\n",
    "group_means = df_salaire.groupby('sk_emploi')['montant_salaire'].mean()\n",
    "ssb = np.sum((group_means - df_salaire['montant_salaire'].mean())**2)\n",
    "\n",
    "# Calculate eta-squared (η²)\n",
    "eta_squared = ssb / tss\n",
    "\n",
    "print(f\"F-statistic: {f_statistic:.2f}\")\n",
    "print(f\"P-value: {p_value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman rank correlation coefficient: 0.23\n"
     ]
    }
   ],
   "source": [
    "#montant salaire et note performance faiblement siginitifactive\n",
    "\n",
    "# Assuming df_perf has 'note_perf_globale' and df_salaire has 'montant_salaire'\n",
    "\n",
    "# Calculate the Spearman rank correlation coefficient and p-value\n",
    "corr_coefficient, p_value = spearmanr(df_factprod['note_perf_globale'], df_salaire['montant_salaire'])\n",
    "\n",
    "print(f\"Spearman rank correlation coefficient: {corr_coefficient:.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.20\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#faiblement significative\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the Pearson correlation coefficient and p-value\n",
    "corr_coeff, p_value = pearsonr(df_employee['anciennete'], df_salaire['montant_salaire'])\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coeff:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman rank correlation coefficient: -0.09\n"
     ]
    }
   ],
   "source": [
    "#négative faible relation entre montant salaire et sk contrat\n",
    "\n",
    "# Assuming df_perf has 'note_perf_globale' and df_salaire has 'montant_salaire'\n",
    "\n",
    "# Calculate the Spearman rank correlation coefficient and p-value\n",
    "corr_coefficient, p_value = spearmanr(df_salaire['sk_contrat'], df_salaire['montant_salaire'])\n",
    "\n",
    "print(f\"Spearman rank correlation coefficient: {corr_coefficient:.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sk_salaire  sk_employee  sk_contrat  sk_emploi  sk_departement  \\\n",
      "0              1            1           1          1               1   \n",
      "1             64           64           1          1               1   \n",
      "2            142          142           1          1               1   \n",
      "3            143          143           1          1               1   \n",
      "4            151          151           1          1               1   \n",
      "...          ...          ...         ...        ...             ...   \n",
      "5912        5681         5092           1        212               3   \n",
      "5913        5685         5619           1        220               3   \n",
      "5914        5604          870           1         73               4   \n",
      "5915        5610         1390           1         73               4   \n",
      "5916        5620         3605           1         73               4   \n",
      "\n",
      "      sk_motif_mobilite  sk_qualification  sk_classification  sk_performance  \\\n",
      "0                     1                 1                  1               1   \n",
      "1                     1                 1                  1               1   \n",
      "2                     1                 1                  1               3   \n",
      "3                     2                 1                  1               1   \n",
      "4                     1                 1                  1               3   \n",
      "...                 ...               ...                ...             ...   \n",
      "5912                  4                11                  3               5   \n",
      "5913                  1                11                  3               5   \n",
      "5914                  1                11                  3               5   \n",
      "5915                  1                11                  3               5   \n",
      "5916                  1                11                  3               5   \n",
      "\n",
      "      sk_date_entree  sk_date_effet  montant_salaire  augmentation_salaire  \\\n",
      "0                  1              1         450000.0               25000.0   \n",
      "1                  1              5         501696.0                   0.0   \n",
      "2                  3             22         425000.0               25000.0   \n",
      "3                  3              6         475000.0               25000.0   \n",
      "4                  9              1         402500.0               22500.0   \n",
      "...              ...            ...              ...                   ...   \n",
      "5912             966              1        4996831.0              509331.0   \n",
      "5913             857              1        4869220.0              636220.0   \n",
      "5914            1124              9        4643042.0             -463158.0   \n",
      "5915             503              9        2884500.0             -112000.0   \n",
      "5916             152              9        5297500.0             -564400.0   \n",
      "\n",
      "      taux_augmentation classification                                emploi  \\\n",
      "0                 5.882            EMP                  CONSEILLER TECHNIQUE   \n",
      "1                 0.000            EMP                  CONSEILLER TECHNIQUE   \n",
      "2                 6.250            EMP                  CONSEILLER TECHNIQUE   \n",
      "3                 5.556            EMP                  CONSEILLER TECHNIQUE   \n",
      "4                 5.921            EMP                  CONSEILLER TECHNIQUE   \n",
      "...                 ...            ...                                   ...   \n",
      "5912             11.350            CAD     EXTERNAL BRAND ENGAGEMENT MANAGER   \n",
      "5913             15.030            CAD     BRAND INTERNAL ENGAGEMENT MANAGER   \n",
      "5914             -9.071            CAD  DIRECTEUR ADMINISTRATIF ET FINANCIER   \n",
      "5915             -3.738            CAD  DIRECTEUR ADMINISTRATIF ET FINANCIER   \n",
      "5916             -9.628            CAD  DIRECTEUR ADMINISTRATIF ET FINANCIER   \n",
      "\n",
      "        departement qualification  \n",
      "0        Production            E2  \n",
      "1        Production            E2  \n",
      "2        Production            E2  \n",
      "3        Production            E2  \n",
      "4        Production            E2  \n",
      "...             ...           ...  \n",
      "5912  Administratif            C3  \n",
      "5913  Administratif            C3  \n",
      "5914     Management            C3  \n",
      "5915     Management            C3  \n",
      "5916     Management            C3  \n",
      "\n",
      "[5917 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.merge(df_salaire, df_classification, on='sk_classification')\n",
    "data = pd.merge(data, df_emploi, on='sk_emploi')\n",
    "data = pd.merge(data, df_dep, on='sk_departement')\n",
    "data = pd.merge(data, df_qual, on='sk_qualification')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 88862997418.05112\n",
      "     classification                                emploi    departement  \\\n",
      "0               EMP                  CONSEILLER TECHNIQUE     Production   \n",
      "1               EMP                  CONSEILLER TECHNIQUE     Production   \n",
      "2               EMP                  CONSEILLER TECHNIQUE     Production   \n",
      "3               EMP                  CONSEILLER TECHNIQUE     Production   \n",
      "4               EMP                  CONSEILLER TECHNIQUE     Production   \n",
      "...             ...                                   ...            ...   \n",
      "5912            CAD     EXTERNAL BRAND ENGAGEMENT MANAGER  Administratif   \n",
      "5913            CAD     BRAND INTERNAL ENGAGEMENT MANAGER  Administratif   \n",
      "5914            CAD  DIRECTEUR ADMINISTRATIF ET FINANCIER     Management   \n",
      "5915            CAD  DIRECTEUR ADMINISTRATIF ET FINANCIER     Management   \n",
      "5916            CAD  DIRECTEUR ADMINISTRATIF ET FINANCIER     Management   \n",
      "\n",
      "     qualification  montant_salaire  salaire_pred  \n",
      "0               E2         450000.0      416000.0  \n",
      "1               E2         501696.0      416000.0  \n",
      "2               E2         425000.0      416000.0  \n",
      "3               E2         475000.0      416000.0  \n",
      "4               E2         402500.0      416000.0  \n",
      "...            ...              ...           ...  \n",
      "5912            C3        4996831.0     4037392.4  \n",
      "5913            C3        4869220.0     2645050.2  \n",
      "5914            C3        4643042.0     4276651.2  \n",
      "5915            C3        2884500.0     4276651.2  \n",
      "5916            C3        5297500.0     4276651.2  \n",
      "\n",
      "[5917 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Use Label Encoding to encode 'classification' and 'emploi' variables to numerical values\n",
    "label_encoder_class = LabelEncoder()\n",
    "label_encoder_emploi = LabelEncoder()\n",
    "label_encoder_departement = LabelEncoder()  # Ajout de l'encodeur pour la colonne 'departement'\n",
    "label_encoder_qualification = LabelEncoder()  # Ajout de l'encodeur pour la colonne 'qualification'\n",
    "\n",
    "data['classification'] = label_encoder_class.fit_transform(data['classification'])\n",
    "data['emploi'] = label_encoder_emploi.fit_transform(data['emploi'])\n",
    "data['departement'] = label_encoder_departement.fit_transform(data['departement'])  # Transformation de 'departement' en valeurs numériques\n",
    "data['qualification'] = label_encoder_qualification.fit_transform(data['qualification'])  # Transformation de 'qualification' en valeurs numériques\n",
    "\n",
    "# Separate features (classification, emploi, departement, qualification) and the target variable (salaire)\n",
    "X = data[['classification', 'emploi', 'departement', 'qualification']]\n",
    "y = data['montant_salaire']\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets (80% for training, 20% for testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the K-nearest neighbors regression model\n",
    "k = 5 # Number of neighbors to consider (you can adjust this value)\n",
    "model = KNeighborsRegressor(n_neighbors=k)\n",
    "\n",
    "# Train the model on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Use the trained model to predict employee salaries\n",
    "predicted_salaries = model.predict(X)\n",
    "\n",
    "# Create a DataFrame with actual salaries, predicted salaries, and the names of emploi and classification\n",
    "result_df = data[['classification', 'emploi', 'departement', 'qualification', 'montant_salaire']].copy()\n",
    "result_df['emploi'] = label_encoder_emploi.inverse_transform(result_df['emploi'])\n",
    "result_df['classification'] = label_encoder_class.inverse_transform(result_df['classification'])\n",
    "result_df['departement'] = label_encoder_departement.inverse_transform(result_df['departement'])  # Inversion de la transformation pour afficher les noms\n",
    "result_df['qualification'] = label_encoder_qualification.inverse_transform(result_df['qualification'])  # Inversion de la transformation pour afficher les noms\n",
    "result_df['salaire_pred'] = predicted_salaries\n",
    "\n",
    "# Display the DataFrame to compare actual salaries with predicted salaries, along with emploi and classification names\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 245583360102.34808\n",
      "      classification  emploi  departement  qualification  montant_salaire  \\\n",
      "0                  3      71            2              7         450000.0   \n",
      "1                  3      71            2              7         501696.0   \n",
      "2                  3      71            2              7         425000.0   \n",
      "3                  3      71            2              7         475000.0   \n",
      "4                  3      71            2              7         402500.0   \n",
      "...              ...     ...          ...            ...              ...   \n",
      "5912               0     118            0              5        4996831.0   \n",
      "5913               0      17            0              5        4869220.0   \n",
      "5914               0      93            1              5        4643042.0   \n",
      "5915               0      93            1              5        2884500.0   \n",
      "5916               0      93            1              5        5297500.0   \n",
      "\n",
      "      salaire_pred  \n",
      "0     4.175162e+05  \n",
      "1     4.175162e+05  \n",
      "2     4.175162e+05  \n",
      "3     4.175162e+05  \n",
      "4     4.175162e+05  \n",
      "...            ...  \n",
      "5912  2.651174e+06  \n",
      "5913  2.648009e+06  \n",
      "5914  2.513835e+06  \n",
      "5915  2.513835e+06  \n",
      "5916  2.513835e+06  \n",
      "\n",
      "[5917 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Utiliser Label Encoding pour encoder les variables 'classification' et 'emploi' en valeurs numériques\n",
    "label_encoder_class = LabelEncoder()\n",
    "label_encoder_emploi = LabelEncoder()\n",
    "data['classification'] = label_encoder_class.fit_transform(data['classification'])\n",
    "data['emploi'] = label_encoder_emploi.fit_transform(data['emploi'])\n",
    "data['departement'] = label_encoder_departement.fit_transform(data['departement'])  # Transformation de 'departement' en valeurs numériques\n",
    "data['qualification'] = label_encoder_qualification.fit_transform(data['qualification']) \n",
    "\n",
    "# Séparer les fonctionnalités (classification et emploi) et la variable cible (salaire)\n",
    "X = data[['classification', 'emploi','departement','qualification']]\n",
    "y = data['montant_salaire']\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test (80% pour l'entraînement, 20% pour le test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Créer un modèle de régression linéaire\n",
    "model = LinearRegression()\n",
    "\n",
    "# Entraîner le modèle sur l'ensemble d'entraînement\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Évaluer les performances du modèle en utilisant l'erreur quadratique moyenne (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Utiliser le modèle entraîné pour prédire le salaire des employés\n",
    "predicted_salaries = model.predict(X)\n",
    "\n",
    "# Créer un DataFrame avec les salaires actuels et les salaires prédits\n",
    "result_df = data[['classification', 'emploi','departement','qualification', 'montant_salaire']].copy()\n",
    "result_df['salaire_pred'] = predicted_salaries\n",
    "\n",
    "\n",
    "\n",
    "# Afficher le DataFrame pour comparer les salaires actuels avec les salaires prédits\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 74603557753.11685\n",
      "      classification  emploi  departement  qualification  montant_salaire  \\\n",
      "0                  3      71            2              7         450000.0   \n",
      "1                  3      71            2              7         501696.0   \n",
      "2                  3      71            2              7         425000.0   \n",
      "3                  3      71            2              7         475000.0   \n",
      "4                  3      71            2              7         402500.0   \n",
      "...              ...     ...          ...            ...              ...   \n",
      "5912               0     118            0              5        4996831.0   \n",
      "5913               0      17            0              5        4869220.0   \n",
      "5914               0      93            1              5        4643042.0   \n",
      "5915               0      93            1              5        2884500.0   \n",
      "5916               0      93            1              5        5297500.0   \n",
      "\n",
      "      salaire_pred  \n",
      "0     4.392346e+05  \n",
      "1     4.392346e+05  \n",
      "2     4.392346e+05  \n",
      "3     4.392346e+05  \n",
      "4     4.392346e+05  \n",
      "...            ...  \n",
      "5912  4.712663e+06  \n",
      "5913  4.593766e+06  \n",
      "5914  4.275014e+06  \n",
      "5915  4.275014e+06  \n",
      "5916  4.275014e+06  \n",
      "\n",
      "[5917 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Use Label Encoding to encode 'classification' and 'emploi' variables to numerical values\n",
    "label_encoder_class = LabelEncoder()\n",
    "label_encoder_emploi = LabelEncoder()\n",
    "label_encoder_departement = LabelEncoder() \n",
    "label_encoder_qualification = LabelEncoder() \n",
    "\n",
    "data['classification'] = label_encoder_class.fit_transform(data['classification'])\n",
    "data['emploi'] = label_encoder_emploi.fit_transform(data['emploi'])\n",
    "data['departement'] = label_encoder_departement.fit_transform(data['departement']) \n",
    "data['qualification'] = label_encoder_qualification.fit_transform(data['qualification'])  \n",
    "\n",
    "# Separate features (classification, emploi, departement, qualification) and the target variable (salaire)\n",
    "X = data[['classification', 'emploi', 'departement', 'qualification']]\n",
    "y = data['montant_salaire']\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets (80% for training, 20% for testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the Decision Tree regression model\n",
    "model = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Train the model on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Use the trained model to predict employee salaries\n",
    "predicted_salaries = model.predict(X)\n",
    "\n",
    "# Create a DataFrame with actual salaries, predicted salaries, and the names of emploi and classification\n",
    "result_df = data[['classification', 'emploi', 'departement', 'qualification', 'montant_salaire']].copy()\n",
    "result_df['emploi'] = label_encoder_emploi.inverse_transform(result_df['emploi'])\n",
    "result_df['classification'] = label_encoder_class.inverse_transform(result_df['classification'])\n",
    "result_df['departement'] = label_encoder_departement.inverse_transform(result_df['departement']) \n",
    "result_df['qualification'] = label_encoder_qualification.inverse_transform(result_df['qualification']) \n",
    "result_df['salaire_pred'] = predicted_salaries\n",
    "\n",
    "# Display the DataFrame to compare actual salaries with predicted salaries, along with emploi and classification names\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "69/69 [==============================] - 18s 47ms/step - loss: 791998300160.0000 - val_loss: 926582505472.0000\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 791531094016.0000 - val_loss: 924741009408.0000\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 782065008640.0000 - val_loss: 897760034816.0000\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 704027492352.0000 - val_loss: 738148679680.0000\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 477361831936.0000 - val_loss: 479543459840.0000\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 300483641344.0000 - val_loss: 400613965824.0000\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 255323619328.0000 - val_loss: 370439716864.0000\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 238101561344.0000 - val_loss: 354886582272.0000\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 228578951168.0000 - val_loss: 345008177152.0000\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 221970513920.0000 - val_loss: 336769286144.0000\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 215836360704.0000 - val_loss: 329038266368.0000\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 210767806464.0000 - val_loss: 324129226752.0000\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 206471217152.0000 - val_loss: 317734584320.0000\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 202268164096.0000 - val_loss: 312485642240.0000\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 198691946496.0000 - val_loss: 308211384320.0000\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 195097559040.0000 - val_loss: 304857743360.0000\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 192053379072.0000 - val_loss: 300905267200.0000\n",
      "Epoch 18/100\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 189701963776.0000 - val_loss: 297723559936.0000\n",
      "Epoch 19/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 187522891776.0000 - val_loss: 295415054336.0000\n",
      "Epoch 20/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 185421447168.0000 - val_loss: 292464590848.0000\n",
      "Epoch 21/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 183570857984.0000 - val_loss: 289954627584.0000\n",
      "Epoch 22/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 181854470144.0000 - val_loss: 288258293760.0000\n",
      "Epoch 23/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 180535345152.0000 - val_loss: 285972398080.0000\n",
      "Epoch 24/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 178653364224.0000 - val_loss: 284766830592.0000\n",
      "Epoch 25/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 177700782080.0000 - val_loss: 283017347072.0000\n",
      "Epoch 26/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 176574234624.0000 - val_loss: 281110577152.0000\n",
      "Epoch 27/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 175291088896.0000 - val_loss: 279825973248.0000\n",
      "Epoch 28/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 174955659264.0000 - val_loss: 279911038976.0000\n",
      "Epoch 29/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 173630701568.0000 - val_loss: 278032941056.0000\n",
      "Epoch 30/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 172983058432.0000 - val_loss: 276645543936.0000\n",
      "Epoch 31/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 172425265152.0000 - val_loss: 275570556928.0000\n",
      "Epoch 32/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 171495915520.0000 - val_loss: 275680362496.0000\n",
      "Epoch 33/100\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 171049664512.0000 - val_loss: 274468290560.0000\n",
      "Epoch 34/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 170704551936.0000 - val_loss: 272964730880.0000\n",
      "Epoch 35/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 170508713984.0000 - val_loss: 272881860608.0000\n",
      "Epoch 36/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 169185738752.0000 - val_loss: 271579987968.0000\n",
      "Epoch 37/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 168686157824.0000 - val_loss: 271794814976.0000\n",
      "Epoch 38/100\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 168043266048.0000 - val_loss: 270798733312.0000\n",
      "Epoch 39/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 168802484224.0000 - val_loss: 270702395392.0000\n",
      "Epoch 40/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 168150745088.0000 - val_loss: 270593376256.0000\n",
      "Epoch 41/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 166792298496.0000 - val_loss: 269264666624.0000\n",
      "Epoch 42/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 166449659904.0000 - val_loss: 269036158976.0000\n",
      "Epoch 43/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 166426869760.0000 - val_loss: 268376244224.0000\n",
      "Epoch 44/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 165641437184.0000 - val_loss: 268340822016.0000\n",
      "Epoch 45/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 165703286784.0000 - val_loss: 269241614336.0000\n",
      "Epoch 46/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 165148229632.0000 - val_loss: 267350802432.0000\n",
      "Epoch 47/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 164403363840.0000 - val_loss: 266582081536.0000\n",
      "Epoch 48/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 164254547968.0000 - val_loss: 266981507072.0000\n",
      "Epoch 49/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 163552919552.0000 - val_loss: 266102669312.0000\n",
      "Epoch 50/100\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 163271933952.0000 - val_loss: 265933717504.0000\n",
      "Epoch 51/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 163213950976.0000 - val_loss: 265288466432.0000\n",
      "Epoch 52/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 162534146048.0000 - val_loss: 264738357248.0000\n",
      "Epoch 53/100\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 162608398336.0000 - val_loss: 265997877248.0000\n",
      "Epoch 54/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 162298036224.0000 - val_loss: 265158819840.0000\n",
      "Epoch 55/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 161618640896.0000 - val_loss: 263994638336.0000\n",
      "Epoch 56/100\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 161544732672.0000 - val_loss: 263835582464.0000\n",
      "Epoch 57/100\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 161542373376.0000 - val_loss: 263097434112.0000\n",
      "Epoch 58/100\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 161284947968.0000 - val_loss: 262960775168.0000\n",
      "Epoch 59/100\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 160665403392.0000 - val_loss: 262578601984.0000\n",
      "Epoch 60/100\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 160366559232.0000 - val_loss: 262764691456.0000\n",
      "Epoch 61/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 160167395328.0000 - val_loss: 262365413376.0000\n",
      "Epoch 62/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 160131989504.0000 - val_loss: 262174801920.0000\n",
      "Epoch 63/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 159932956672.0000 - val_loss: 261549637632.0000\n",
      "Epoch 64/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 159352193024.0000 - val_loss: 261742739456.0000\n",
      "Epoch 65/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 159044124672.0000 - val_loss: 260668833792.0000\n",
      "Epoch 66/100\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 158868176896.0000 - val_loss: 261002493952.0000\n",
      "Epoch 67/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 159537086464.0000 - val_loss: 261028593664.0000\n",
      "Epoch 68/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 158383439872.0000 - val_loss: 260762664960.0000\n",
      "Epoch 69/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 158262362112.0000 - val_loss: 260363993088.0000\n",
      "Epoch 70/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 157597106176.0000 - val_loss: 260459118592.0000\n",
      "Epoch 71/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 157487611904.0000 - val_loss: 259465216000.0000\n",
      "Epoch 72/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 157279485952.0000 - val_loss: 259862102016.0000\n",
      "Epoch 73/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 156968878080.0000 - val_loss: 259021176832.0000\n",
      "Epoch 74/100\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 156662972416.0000 - val_loss: 259125641216.0000\n",
      "Epoch 75/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 156589998080.0000 - val_loss: 258971418624.0000\n",
      "Epoch 76/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 156244934656.0000 - val_loss: 258521038848.0000\n",
      "Epoch 77/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 155876065280.0000 - val_loss: 257994080256.0000\n",
      "Epoch 78/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 155826782208.0000 - val_loss: 258761949184.0000\n",
      "Epoch 79/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 155660484608.0000 - val_loss: 257716486144.0000\n",
      "Epoch 80/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 155288584192.0000 - val_loss: 258683781120.0000\n",
      "Epoch 81/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 154753024000.0000 - val_loss: 257162444800.0000\n",
      "Epoch 82/100\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 155138424832.0000 - val_loss: 257374814208.0000\n",
      "Epoch 83/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 155800764416.0000 - val_loss: 257532477440.0000\n",
      "Epoch 84/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 154392182784.0000 - val_loss: 257003175936.0000\n",
      "Epoch 85/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 154071613440.0000 - val_loss: 256362856448.0000\n",
      "Epoch 86/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 153779912704.0000 - val_loss: 255969116160.0000\n",
      "Epoch 87/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 153605111808.0000 - val_loss: 256731414528.0000\n",
      "Epoch 88/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 153481789440.0000 - val_loss: 255732695040.0000\n",
      "Epoch 89/100\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 153428148224.0000 - val_loss: 257136115712.0000\n",
      "Epoch 90/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 153237274624.0000 - val_loss: 256468205568.0000\n",
      "Epoch 91/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 152923766784.0000 - val_loss: 254982668288.0000\n",
      "Epoch 92/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 152589074432.0000 - val_loss: 255320031232.0000\n",
      "Epoch 93/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 152308858880.0000 - val_loss: 254534418432.0000\n",
      "Epoch 94/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 152343134208.0000 - val_loss: 254695882752.0000\n",
      "Epoch 95/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 152008146944.0000 - val_loss: 253970710528.0000\n",
      "Epoch 96/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 151769071616.0000 - val_loss: 253986095104.0000\n",
      "Epoch 97/100\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 151852711936.0000 - val_loss: 253922557952.0000\n",
      "Epoch 98/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 151470112768.0000 - val_loss: 253952229376.0000\n",
      "Epoch 99/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 151834574848.0000 - val_loss: 253358571520.0000\n",
      "Epoch 100/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 151027826688.0000 - val_loss: 253081944064.0000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 213028847616.0000\n",
      "Mean Squared Error: 213028847616.0\n",
      "185/185 [==============================] - 1s 982us/step\n",
      "      classification  emploi  departement  qualification  montant_salaire  \\\n",
      "0                  3      71            2              7         450000.0   \n",
      "1                  3      71            2              7         501696.0   \n",
      "2                  3      71            2              7         425000.0   \n",
      "3                  3      71            2              7         475000.0   \n",
      "4                  3      71            2              7         402500.0   \n",
      "...              ...     ...          ...            ...              ...   \n",
      "5912               0     118            0              5        4996831.0   \n",
      "5913               0      17            0              5        4869220.0   \n",
      "5914               0      93            1              5        4643042.0   \n",
      "5915               0      93            1              5        2884500.0   \n",
      "5916               0      93            1              5        5297500.0   \n",
      "\n",
      "      salaire_pred  \n",
      "0     4.198754e+05  \n",
      "1     4.198754e+05  \n",
      "2     4.198754e+05  \n",
      "3     4.198754e+05  \n",
      "4     4.198754e+05  \n",
      "...            ...  \n",
      "5912  2.943942e+06  \n",
      "5913  2.972632e+06  \n",
      "5914  2.578947e+06  \n",
      "5915  2.578947e+06  \n",
      "5916  2.578947e+06  \n",
      "\n",
      "[5917 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Séparer les fonctionnalités (classification et emploi) et la variable cible (salaire)\n",
    "X = data[['classification', 'emploi','departement','qualification']]\n",
    "y = data['montant_salaire']\n",
    "\n",
    "# Normaliser les fonctionnalités\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test (80% pour l'entraînement, 20% pour le test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Créer le modèle de réseau de neurones\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(1) \n",
    "])\n",
    "\n",
    "# Compiler le modèle en spécifiant la fonction de perte et l'optimiseur\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entraîner le modèle sur l'ensemble d'entraînement\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=55, validation_split=0.2)\n",
    "\n",
    "\n",
    "# Évaluer les performances du modèle sur l'ensemble de test\n",
    "mse = model.evaluate(X_test,y_test)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Utiliser le modèle entraîné pour prédire le salaire des employés\n",
    "predicted_salaries = model.predict(X)\n",
    "\n",
    "# Créer un DataFrame avec les salaires actuels et les salaires prédits\n",
    "result_df = data[['classification', 'emploi','departement','qualification', 'montant_salaire']].copy()\n",
    "result_df['salaire_pred'] = predicted_salaries\n",
    "\n",
    "result_df['salaire_pred'] = result_df['salaire_pred'].astype(result_df['montant_salaire'].dtype)\n",
    "\n",
    "# Afficher le DataFrame pour comparer les salaires actuels avec les salaires prédits\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "119/119 [==============================] - 1s 3ms/step - loss: 791917101056.0000 - val_loss: 926109859840.0000\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 788190724096.0000 - val_loss: 915495321600.0000\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 760357322752.0000 - val_loss: 860684156928.0000\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 670736056320.0000 - val_loss: 727841308672.0000\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 514078539776.0000 - val_loss: 553236692992.0000\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 359906115584.0000 - val_loss: 435327860736.0000\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 281740705792.0000 - val_loss: 391941980160.0000\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 255331008512.0000 - val_loss: 373600681984.0000\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 243624083456.0000 - val_loss: 362234445824.0000\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 235740102656.0000 - val_loss: 353423917056.0000\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 229543280640.0000 - val_loss: 346388824064.0000\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 224379092992.0000 - val_loss: 339714211840.0000\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 220420980736.0000 - val_loss: 334482636800.0000\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 216354996224.0000 - val_loss: 329676849152.0000\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 212674101248.0000 - val_loss: 325763694592.0000\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 209728454656.0000 - val_loss: 322119303168.0000\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 206885928960.0000 - val_loss: 318754095104.0000\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 204268797952.0000 - val_loss: 315953283072.0000\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 201871523840.0000 - val_loss: 312972083200.0000\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 199683080192.0000 - val_loss: 310192734208.0000\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 197631246336.0000 - val_loss: 307649871872.0000\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 195528900608.0000 - val_loss: 305235263488.0000\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 193802403840.0000 - val_loss: 302952611840.0000\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 192224313344.0000 - val_loss: 300918603776.0000\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 190641504256.0000 - val_loss: 299078320128.0000\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 188997419008.0000 - val_loss: 297168338944.0000\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 187671101440.0000 - val_loss: 295171260416.0000\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 186424213504.0000 - val_loss: 293477253120.0000\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 185285001216.0000 - val_loss: 292378443776.0000\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 184097374208.0000 - val_loss: 290857484288.0000\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 183007756288.0000 - val_loss: 289131036672.0000\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 182097805312.0000 - val_loss: 288391790592.0000\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 180935966720.0000 - val_loss: 286794842112.0000\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 179759939584.0000 - val_loss: 285489037312.0000\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 178955026432.0000 - val_loss: 284013756416.0000\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 178065801216.0000 - val_loss: 282700185600.0000\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 177152491520.0000 - val_loss: 281850380288.0000\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 176608657408.0000 - val_loss: 280965349376.0000\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 175785656320.0000 - val_loss: 279605444608.0000\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 175056027648.0000 - val_loss: 279184703488.0000\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 174366752768.0000 - val_loss: 278023110656.0000\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 173861732352.0000 - val_loss: 277477163008.0000\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 173215989760.0000 - val_loss: 276524564480.0000\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 172728467456.0000 - val_loss: 275535396864.0000\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 171944132608.0000 - val_loss: 275145981952.0000\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 171473387520.0000 - val_loss: 274440519680.0000\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 171060920320.0000 - val_loss: 273945772032.0000\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 170557587456.0000 - val_loss: 273341448192.0000\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 170561961984.0000 - val_loss: 272758587392.0000\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 169632841728.0000 - val_loss: 272547364864.0000\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 169247866880.0000 - val_loss: 272096722944.0000\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 168821145600.0000 - val_loss: 271895969792.0000\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 168538423296.0000 - val_loss: 271325937664.0000\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 168269496320.0000 - val_loss: 270776107008.0000\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 167769260032.0000 - val_loss: 270349729792.0000\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 167447298048.0000 - val_loss: 269952352256.0000\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 167315013632.0000 - val_loss: 269675053056.0000\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 166872809472.0000 - val_loss: 269300432896.0000\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 166592561152.0000 - val_loss: 269316718592.0000\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 166398967808.0000 - val_loss: 268886753280.0000\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 166030163968.0000 - val_loss: 268671598592.0000\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 165696749568.0000 - val_loss: 268391448576.0000\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 165579735040.0000 - val_loss: 267974311936.0000\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 165338988544.0000 - val_loss: 267789500416.0000\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 164903878656.0000 - val_loss: 267437391872.0000\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 164844470272.0000 - val_loss: 267038621696.0000\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 164486955008.0000 - val_loss: 267165450240.0000\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 164437786624.0000 - val_loss: 266938679296.0000\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 164120985600.0000 - val_loss: 266671243264.0000\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 164032299008.0000 - val_loss: 266552066048.0000\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 163521396736.0000 - val_loss: 266311516160.0000\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 163419766784.0000 - val_loss: 266368450560.0000\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 163411263488.0000 - val_loss: 266038919168.0000\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 163136716800.0000 - val_loss: 265805398016.0000\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 162809118720.0000 - val_loss: 265401991168.0000\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 162699788288.0000 - val_loss: 265210445824.0000\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 162541928448.0000 - val_loss: 264761884672.0000\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 162366062592.0000 - val_loss: 264687828992.0000\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 162245378048.0000 - val_loss: 264738504704.0000\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 162189819904.0000 - val_loss: 264608464896.0000\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 161982562304.0000 - val_loss: 264321040384.0000\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 161620869120.0000 - val_loss: 263712800768.0000\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 161505804288.0000 - val_loss: 264420179968.0000\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 161487142912.0000 - val_loss: 263714881536.0000\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 161231060992.0000 - val_loss: 263730839552.0000\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 161087291392.0000 - val_loss: 263533035520.0000\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 160655622144.0000 - val_loss: 263566786560.0000\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 160795705344.0000 - val_loss: 263121846272.0000\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 160358318080.0000 - val_loss: 263199817728.0000\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 160198377472.0000 - val_loss: 263089569792.0000\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 160190185472.0000 - val_loss: 262335954944.0000\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 159728320512.0000 - val_loss: 262544982016.0000\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 159723847680.0000 - val_loss: 262402981888.0000\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 159603081216.0000 - val_loss: 262100631552.0000\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 159465766912.0000 - val_loss: 262011125760.0000\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 159332990976.0000 - val_loss: 261924438016.0000\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 158946017280.0000 - val_loss: 261717639168.0000\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 158799773696.0000 - val_loss: 261446270976.0000\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 158742052864.0000 - val_loss: 261302140928.0000\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 158432034816.0000 - val_loss: 261059723264.0000\n",
      "185/185 [==============================] - 0s 1ms/step\n",
      "Accuracy: 0.5675173229677202\n",
      "      classification  emploi  departement  qualification  Actual Salary  \\\n",
      "0                  3      71            2              7      450000.00   \n",
      "1                  3      71            2              7      501696.00   \n",
      "2                  3      71            2              7      425000.00   \n",
      "3                  3      71            2              7      475000.00   \n",
      "4                  3      71            2              7      402500.00   \n",
      "...              ...     ...          ...            ...            ...   \n",
      "5912               0     118            0              5     4996831.00   \n",
      "5913               0      17            0              5     4869220.00   \n",
      "5914               0      93            1              5     4643042.00   \n",
      "5915               0      93            1              5     2884500.00   \n",
      "5916               0      93            1              5     5297500.00   \n",
      "\n",
      "     Actual Salary Class  Predicted Salary Predicted Salary Class  \n",
      "0                 medium         401819.59                    low  \n",
      "1                   high         401819.59                    low  \n",
      "2                 medium         401819.59                    low  \n",
      "3                 medium         401819.59                    low  \n",
      "4                    low         401819.59                    low  \n",
      "...                  ...               ...                    ...  \n",
      "5912                high        2774744.75                   high  \n",
      "5913                high        2757879.00                   high  \n",
      "5914                high        2507381.75                   high  \n",
      "5915                high        2507381.75                   high  \n",
      "5916                high        2507381.75                   high  \n",
      "\n",
      "[5917 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "#on', 'emploi', and 'departement' variables to numerical values\n",
    "label_encoder_class = LabelEncoder()\n",
    "label_encoder_emploi = LabelEncoder()\n",
    "label_encoder_departement = LabelEncoder()\n",
    "\n",
    "data['classification'] = label_encoder_class.fit_transform(data['classification'])\n",
    "data['emploi'] = label_encoder_emploi.fit_transform(data['emploi'])\n",
    "data['departement'] = label_encoder_departement.fit_transform(data['departement'])\n",
    "data['qualification'] = label_encoder_departement.fit_transform(data['qualification'])\n",
    "\n",
    "# Separate features (classification, emploi, departement, qualification) and the target variable (montant_salaire)\n",
    "X = data[['classification', 'emploi', 'departement', 'qualification']]\n",
    "y = data['montant_salaire']\n",
    "\n",
    "\n",
    "\n",
    "# Separate features (classification, emploi, departement, qualification) and the target variable (montant_salaire)\n",
    "X = data[['classification', 'emploi', 'departement', 'qualification']]\n",
    "y = data['montant_salaire']\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets (80% for training, 20% for testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the neural network model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model on the training set\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Use the trained model to predict employee salaries\n",
    "predicted_salaries = model.predict(X)\n",
    "\n",
    "# Calculate accuracy based on salary ranges\n",
    "salary_percentiles = y.quantile([0.33, 0.66])\n",
    "low_salary = salary_percentiles.iloc[0]\n",
    "high_salary = salary_percentiles.iloc[1]\n",
    "\n",
    "actual_salary_class = pd.cut(y, bins=[0, low_salary, high_salary, y.max()], labels=['low', 'medium', 'high'])\n",
    "predicted_salary_class = pd.cut(predicted_salaries.flatten(), bins=[0, low_salary, high_salary, y.max()], labels=['low', 'medium', 'high'])\n",
    "\n",
    "accuracy = accuracy_score(actual_salary_class, predicted_salary_class)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Create a DataFrame with actual salaries, predicted salaries, and the names of emploi and classification\n",
    "result_df = pd.DataFrame({'classification':data['classification'],'emploi':data['emploi'],'departement':data['departement'],'qualification':data['qualification'],'Actual Salary': y, 'Actual Salary Class': actual_salary_class, 'Predicted Salary': predicted_salaries.flatten(), 'Predicted Salary Class': predicted_salary_class})\n",
    "result_df['Predicted Salary'] = result_df['Predicted Salary'].astype(data['montant_salaire'].dtype)\n",
    "\n",
    "\n",
    "# Inverse transform the label encoded columns back to their original categorical values\n",
    "result_df['Actual Salary Class'] = actual_salary_class\n",
    "result_df['Predicted Salary Class'] = predicted_salary_class\n",
    "# Format the display of float values with two decimals\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "print(result_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Créez un DataFrame à partir des données\n",
    "df = pd.DataFrame(result_df)  # Assurez-vous d'avoir correctement défini \"data\" comme vous l'avez montré\n",
    "\n",
    "# Exportez le DataFrame vers un fichier CSV\n",
    "df.to_csv('resultats_predictionsfinal.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c5e48f84046969b800ff52f6d80523bcd1ca3fb1a99f1449e4197bf6c73dc096"
  },
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
